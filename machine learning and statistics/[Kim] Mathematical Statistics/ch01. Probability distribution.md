I. 확률 분포
===



## 1. 확률의 뜻과 성질



#### 정의 1.1.1 : 표본공간 (Sample Space), 사건 (event), 확률(probability)

- 표본공간  $S$ : 가능한 모든 관측결과들의 집합.
- 사건 $A$ : 표본공간의 부분집합
- 확률 $P(A)$ : 각 사건의가능성을 수량화한것.



#### Notation 

- 특별한 언급이 없으면 $S$ 를 표본공간, $A,\,B,\,A_1,\,A_2,\ldots,\,B_1,\,B_2,\ldots$ 를 사건으로 한다.



#### 확률의 공리 1.1.2

1. $P(A)\ge 0$.
2. $P(S) =1$.
3. $A_i \subset S,\, A_j \subset S$ 이며 $A_i \cap A_j = \varnothing \implies P(A_i \cup A_j)=P(A_i)+P(A_j)$.  



#### Theorem 1.1.3 확률의 기본 성질

(a) 각 사건 $A$ 에 대해 $0 \le P(A)\le 1$ 이며 $P(\varnothing)=0$ 이다.

(b) 사건 $A$ 에 대해 $P(A^C)=1-P(A)$ 이다.

(c) $ A \subset B \implies P(A) \le P(B)$. 

---

*(proof)* (a) $S=A\cup A^C$ 이며 $A \cap A^C = \varnothing$ 이므로 $P(S)=1=P(A)+P(A^C)$ 이다. $P(A)=1-P(A^C)\le 1$ 이며 $P(A)\ge 0$ 임은 공리 1.1.2. 

(b) see proof (a)

(c) $A \cap (B-A)=\varnothing$, $A \cup (B-A)=B$ 이므로 $P(B)=P(A)+P(B-A) \ge P(A)$. $\square$ 



#### Theorem 1.1.4 합사건의 확률

$\mathcal{A}=\{A_1,\,A_2,\ldots\}$ 가 사건들의 집합 이고 $P^{\mathcal{A}}_k$ 는 $\mathcal{A}$ 에서 $k$ 개의 사건들을 순서와 무관하게 중복되지 않게 선택하여 그 교집합의 확률을 더한것이라고 하자. 즉 $\mathcal{A}=\{A_1,\,A_2,\,A_3\}$ 라면 $P^{\mathcal{A}}_2=P(A_1 \cap A_2)+P(A_2 \cap A_3)+P(A_3 \cap A_1)$ 이다. 이 때 다음이 성립한다.

(a) $\mathcal{A}$ 가 $n$ 개의 사건들의 집합 일 때,
$$
P (A_1 \cup \cdots \cup A_n)=P_1 +(-1)P_2 + \cdots + (-1)^{n-1}P_n \tag{1}
$$
(b) Countable subadditivity
$$
P(A_1 \cup A_2 \cup \cdots) \le P(A_1)+P(A_2)+ \cdots \tag{2}
$$

---

*(proof)* (a) Induction으로 증명한다. $n=2$ 일 때 $P(A_1 \cup A_2) = P(A_1)+P(A_2)-P(A_1 \cap A_2)$ 임을 보이자. 우선 다음이 성립함을 알 수 있다.
$$
\begin{align}
A_1 \cup A_2 &= (A_1-A_2)\cup (A_2-A_1) \cup (A_1 \cap A_2)\,,\\
A_1 &= (A_1 -A_2) \cup (A_1 \cap A_2)\,,\\
A_2 &= (A_2-A_1)\cup (A_1 \cup A_2)\;.\\
(A_1 -A_2) \cap (A_2-A_1)&= \varnothing\,,\\
(A_1-A_2) \cap (A_1 \cap A_2) &= \varnothing \,,\\
(A_2-A_1)\cap (A_1 \cap A_2) &= \varnothing\;.

\end{align}
$$
따라서,
$$
\begin{align}
P(A_1 \cup A_2) & = P(A_1-A_2)+P(A_2-A_1)+P(A_1 \cap A_2)\\
&= P(A_1-A_2)+P(A_1\cap A_2)+ P(A_2-A_1)+P(A_1 \cap A_2)-P(A_1\cap A_2)\,\\
&=P(A_1)+P(A_2)-P(A_1 \cap A_2)\;.

\end{align}
$$
이제 $\mathcal{A}$ 가 $n$ 개 일 때 (1) 이 성립함을 가정한다. $\mathcal{A'}=\mathcal{A}\cup \{A_{n+1}\}$ 이라 하자. 
$$
\begin{align}
P(A_1 \cup \cdots \cup A_{n+1})&=P((A_1 \cup \cdots \cup A_n)\cup A_{n+1})  \\
&=P(A_1\cup \cdots  \cup A_n) + P(A_{n+1})-P((A_1\cup \cdots \cup A_n)\cap A_{n+1})\\
&= P^{\mathcal{A}}_1 + \cdots +(-1)^{n+1}P^{\mathcal{A}}_n + P(A_{n+1})-P\left(\bigcup_{k=1}^n (A_k \cap A_{n+1}) \right) &\\
&=P_1^{\mathcal{A}'}+(-1)P_2^\mathcal{A}+ \cdots + (-1)^{n+1}P_n^{\mathcal{A}}-P\left(\bigcup_{k=1}^n (A_k \cap A_{n+1}) \right)

\end{align}
$$
여기서 $B_k = A_k \cap A_{n_1},\, \mathcal{B}=\{B_1,\ldots,\,B_n \}$ 이라 하면,
$$
\begin{align}
P\left(\bigcup_{k=1}^n (A_k \cap A_{n+1}) \right) &= P\left( B_1 \cup \cdots \cup B_n \right) \\
&= P_1^\mathcal{B}+\cdots + (-1)^{n+1}P_n^{\mathcal{B}}

\end{align}
$$
이다. 또한 $P_k^\mathcal{A} + P_{k-1}^\mathcal{B}=P_k^{\mathcal{A'}}$ 이므로,
$$
\begin{align}
P(A_1 \cup \cdots \cup A_{n+1})&=P_1^{\mathcal{A}'}+(-1)P_2^\mathcal{A}+ \cdots + (-1)^{n+1}P_n^{\mathcal{A}} -P_1^\mathcal{B}-\cdots -(-1)^{n+1}P_n^\mathcal{B} \\
&=P_1^{\mathcal{A'}}+(-1)P_2^\mathcal{A'}+\cdots + (-1)^{n+2}P_{n+1}^{\mathcal{A}'}
\end{align}
$$
이다. 

(b) $B_i$ 를 $B_1=A_1$, $B_k=A_k-\left(\bigcup_{j=1}^{k-1}A_j\right)$ 로 정의하면 $i\ne j \implies B_i \cap B_j = \varnothing$ 이며 $\bigcup_{j=1}^k B_k = \bigcup_{j=1}^k A_k$ 임을 알 수 있다. 또한 $B_j \subset A_j$ 이므로 $P(B_j)\le P(A_j)$ 이다. 따라서,
$$
P\left(\bigcup_{j=1} A_j \right) = P\left(\bigcup_{j=1} B_j\right)=\sum_{j=1}P(B_j ) \le \sum_{j=1} P(A_j)
$$
이다.



#### Theorem 1.1.5 확률측도의 연속성

(a) $\displaystyle A_1 \subseteq A_2 \subseteq \cdots \subseteq A_n \subseteq \cdots \implies P\left(\bigcup_{n=1}^\infty A_n \right)=\lim_{n\to \infty} P(A_n)$ 

(b) $\displaystyle B_1 \supseteq B_2 \supseteq \cdots \supseteq B_n \supseteq \cdots \implies P\left(\bigcap_{n=1}^\infty B_n \right) = \lim_{\infty}P(B_n)$ 

---

*(proof)* (a) $C_1=A_1,\, C_k = A_k-A_{k-1}$ 이라 정의하면 다음이 성립한다.
$$
i \ne j \implies C_i \cap C_j = \varnothing\,, \\ 
\bigcup_{i=1}^\infty C_i = \bigcup_{i=1}^\infty A_i\,. \\
$$
여기서,
$$
C_k \cup A_{k-1}=(A_k -A_{k-1})\cup A_{k-1}=(A_k \cap A_{k-1})\cup A_{k-1}=A_k
$$
이며 $C_k \cup A_{k-1}=\varnothing$ 이므로 $P(A_k)=P(C_k)+P(A_{k-1})$.  따라서,
$$
P(C_k)=P(A_k)-P(A_{k-1})
$$
이다. 그러므로,
$$
P\left(\bigcup_{n=1}^\infty A_n\right) = P\left(\bigcup_{n=1}^\infty C_n\right)=\sum_{n=1}^\infty P(C_n)=\lim_{n\to\infty}\sum_{k=1}^n P(C_k)= \lim_{n\to \infty} P(A_n)\;.
$$
(b) Let $D_j = {B_{j}}^C$ . Then, $P(D_j)=1-P(B_j)$ 이며 $\{D_j\}$ 는 (a) 의 성질을 만족한다. 또한,
$$
\left(\bigcup_{k=1}^\infty D_k\right)^C = \bigcap_{k=1}^\infty B_k
$$
이므로,
$$
P\left( \bigcap_{n=1}^\infty B_n\right)=1-P\left(\bigcup_{n=1}^\infty D_n\right)=1-\lim_{n\to\infty} P(D_n)=\lim_{n\to \infty} P(B_n)\;.
$$
이 성립한다. $\square$



<b>Example 1.1.6 </b> 표본공간이 $S=[0,\,1]$ 이고 $P((a,\,b])=b-a$ 일 때 $x\in S$ 인 한 점의 확률 $P(\{x\})$ 는
$$
P(\{x\})=P\left( \bigcap_{n=1}^\infty \left(x-\dfrac{1}{n},\, x+\dfrac{1}{n}\right] \right) = \lim_{n\to\infty} P\left(\left( x-\dfrac{1}{n},\,x+\dfrac{1}{n}\right]\right)=\lim_{n\to \infty}\dfrac{2}{n}=0\;.
$$


## 2. 조건부확률과 독립성.



### Definition 1.2.1 조건부확률

사건 $A$ 가 주어진 경우에 사건 $B$ 가 일어날 확률 $P(B|A)$ 는 $P(A) > 0$ 인 경우 다음과 같다.
$$
P(B|A)=\dfrac{P(A \cap B)}{P(A)} 
$$


#### Theorem 1.2.2 조건부확률의 성질.

(a) $P(A >0 ),\, P(B)>0$ 일 때 다음이 성립한다.
$$
P(A \cap B) = P(B|A) P(A)=P(A|B)P(B)\;.
$$
(b) $\{A_1,\ldots,\,A_2,\ldots\}$ 가 표본공간 $S$ 를 분할한다면, 즉 $i \ne j \implies A_i \ne A_j$ 이며 $\bigcup_{i=1}^\infty A_i =S$ 이면 다음이 성립한다.
$$
P(B)=\sum_{n=1}^\infty P(B|A_n)P(A_n)\;.
$$

---

*(proof)* (a) 는 trivial 하다. 

(b) $B=B \cap S = B \cap \left(\bigcup_{n=1}^{\infty} A_n\right) = \bigcup_{n=1}^n (B \cap A_n)$ 이며, $i\ne j$ 일 때,
$$
(B \cap A_i) \cap (B \cap A_j)=B \cap (A_i \cap A_j)=\varnothing 
$$
이므로,
$$
P(B) = P\left( B  \cap S\right) = \sum_{n=1}^\infty P(B \cap A_n) =\sum_{n=1}^\infty P(B | A_n)P(A_n)
$$


#### Theorem 1.2.3 베이즈의 정리 (Bayes' theorem)

사건 $A_1,\,A_2,\ldots$ 가 표본공간 $S$ 를 분할하고 $P(A_i)>0$ for all $i$ and $P(B)>0$ 일 때 다음이 성립한다. 
$$
P(A_j|B)\propto P(B|A_j)P(A_j)\;.
$$
이 때의 비례상수는 좌변의 합이 $1$ 임으로 부터 결정된다.

---

*(proof)* $P(A_j|B)P(B)=P(B|A_j)P(A_j)$ 이므로 
$$
P(A_j|B) = \dfrac{P(B|A_j)P(A_j)}{P(B)} =\dfrac{P(B|A_j)P(A_j)}{\displaystyle \sum_{n=1}^\infty P(B|A_j)P(A_j)}=cP(B|A_j)P(A_j)
$$
이다.  $\square$



#### 정의 1.2.4 사건의 독립성

$n$ 개의 사건 $A_1,\ldots,\,A_n$ 이 다음 조건을 만족하면 이 사건들이 독립이라 한다.
$$
P(A_1 \cap \cdots \cap A_n)=\prod_{k=1}^n P(A_k)
$$

#### Lemma 1.2.5

사건 $A,\,B$ 가 독립이면 $A,\,B^C$ 도 서로 독립이다.

---

*(proof)* $P(A \cap B)=P(A)P(B)$ 이다. $A=(A \cap B) \cup (A \cap B^C)$ 이며 $(A \cap B) \cap (A \cap B^C)=\varnothing$ 이므로,
$$
P(A)=P(A\cap B)+P(A \cap B^C)
$$
이다. 따라서,
$$
P(A \cap B^C)=P(A)-P(A\cap B)=P(A)-P(A)P(B)=P(A)(1-P(B))=P(A)P(B^C)
$$
이므로 $A \cap B^C$ 도 독립이다. $\square$



## 1.3 확률변수와 확률분포



#### Definition 1.3.1 이산형 자료의 확률밀도함수.

확률변수 $X$ 가 가질 수 있는 값들의 집합이 countable 로서 $\{x_1,\,x_2,\ldots\}$ 와 같이 표현될 때 그 확률변수를 이산형(discrete type) 이라 하고 각각의 값에 그 값을 가질 확률을 대응시키는 아래와 같은 꼴의 함수 $f$ 를 **확률질량함수 (probability mass function)** 혹은 **확률밀도함수 (probability density function)** 이라 한다. 약자로 pdf 로 쓰기도 한다.
$$
f(x_k)=P(X=x_k)\;.
$$
확률밀도함수는 다음 성질을 만족한다. 이 때 $\mathcal{X}=\{x_1,\,x_2,\ldots\}$ 라 하자. 

(a) $\forall x\in \mathcal{X},\, f(x) \ge 0$. $\forall x\not\in \mathcal{X},\, f(x)=0$. 

(b) $\displaystyle \sum_{x\in \mathcal{X}}f(x)=1$. 

(c) $\displaystyle \sum_{x \in \mathcal{X},\, a \le x \le b} f(x) = P(a \le X\le b)$. 



#### Definition 1.3.2 연속형 자료의 확률밀도함수

확률변수 $X$ 가 가질 수 있는 값들의 집합이 어떤 실수의 구간이며 그에 관한 확률이 적분으로 주어질 때, 그 확률변수를 연속형(continuous type) 이라 하고 확률을 정해주는 아래와 같은 함수 $f$ 를 **확률밀도함수 (probability density function)** 이라 한다.
$$
\int_a^b f(x)\,dx=P(a\le X\le b)\,,\qquad(-\infty<a<b<+\infty)
$$
이 확률밀도한수는 다음 성질을 만족한다.

(a) $f(x)\ge 0,\,\forall x \in \mathbb{R}$ 

(b) $\displaystyle \int_{-\infty}^\infty f(x) \,dx =1$.



#### Convention : $X \sim f$

확률변수 $X$ 의 분포가 확률밀도함수 $f$ 로 주어진다는 뜻이다.



#### Definition 1.3.3 : 지표함수 (Indicator Function)

연속형 확률변수의 확률분포를 나타낼 때 다음과 같이 정의되는 함수를 **지표함수** 라 한다.
$$
\operatorname{I}_A (x)=\left\{\begin{array}{ll} 1 \quad &x\in A\,,\\0 &\text{Otherwise}\,. \end{array}\right.
$$


## 1.4. 확률분포의 특성치



#### Definition 1.4.1 : 평균(mean)

확률변수 $X$ 의 확률밀도함수가 $f$ 일 때, $X$ 의 확률분포의 평균 $\mu$ 는 다음과 같다.
$$
\mu = \left\{\begin{array}{ll} \displaystyle \sum_{x}xf(x) &\text{if }X\text{ is discrete type}\,,\\ & \\ \displaystyle \int_{-\infty}^\infty xf(x)\,dx \quad &\text{if } X \text{ is continuous type}. \end{array} \right.
$$




#### Definition 1.4.2 : 기대값 (Expected value)

확률변수 $X$ 의 함수 $g(X)$ 에 대해 $g(X)$ 의 기댓값 $\mathbb{E}[g(X)]$ 는 다음과 같이 정의된다.
$$
\mathbb{E}[g(X)] = \left\{\begin{array}{ll} \displaystyle \sum_{x}g(x)f(x) &\text{if }X\text{ is discrete type}\,,\\ & \\ \displaystyle \int_{-\infty}^\infty g(x)f(x)\,dx \quad &\text{if } X \text{ is continuous type}. \end{array} \right.
$$

- $\mu=\mathbb{E}[X]$ 이다. 



#### Defintion 1.4.3 : 분산(Variance) 와 표준펀차 (Standard Deviation)

확률변수 $X$ 의 확률밀도함수 $f$ 에 대해 평균이 $\mu$ 일 때, 확률분포의 **분산(variance)** $\operatorname{Var}(X)$ 와 **표준편차 (standard deviation)** $\operatorname{Sd}(X)$ 는 다음과 같이 정의된다.
$$
\begin{align}
\operatorname{Var}(X) &= \mathbb{E}[(X-\mu)^2]= \left\{\begin{array}{ll} \displaystyle \sum_{x} (x-\mu)^2f(x) &\text{if }X\text{ is discrete type}\,,\\ & \\ \displaystyle \int_{-\infty}^\infty (x-\mu)^2f(x)\,dx \quad &\text{if } X \text{ is continuous type}. \end{array} \right. \\
\operatorname{Sd}(X) &=\sqrt{\operatorname{Var(X)}}\;.
\end{align}
$$
 

#### Theorem 1.4.4 : 기대값의 성질

(a) (Linearity 1.) $\mathbb{E}[aX+b]=a\mathbb{E}[X]+b$. 

(b) (Linearity 2.) $\mathbb{E}[c_1g_1(X)+c_2g_2(X)]=c_1\mathbb{E}[g_1(X)]+c_2 \mathbb{E}[g_2(X)]$.

(c) (Monotonicity) $g_1 (X)\le g_2 (X) \implies \mathbb{E}[g_1(X)]\le \mathbb{E}[g_2(X)]$. 

----

*proof is trivial*



#### Theorem 1.4.5 : 분산의 성질

(a) $\operatorname{Var}(aX+b)=a^2 \operatorname{Var}(X)$. 

(b) $\operatorname{Var}(X)=\mathbb{E}[X^2]-\left(\mathbb{E}[X]\right)^2$. 

----

*(proof)*

(a)  $\mathbb{E}[aX+b]=a\mu+b$, 
$$
\begin{align}
\operatorname{Var}(aX+b)  & = \mathbb{E}[(aX+b-a\mu-b)^2]=\mathbb{E}[a^2(X-\mu)^2]=a^2\mathbb{E}[(X-\mu)^2]=a^2\operatorname{Var}(X)\,,
\end{align}
$$
(b)
$$
\operatorname{Var}(X)=\mathbb{E}[(X-\mu)^2]=\mathbb{E}[X^2]-2\mu\mathbb{E}[X]+\mu^2=\mathbb{E}[X^2]-\mu^2=\mathbb{E}[X^2]-\left(\mathbb{E}[X]\right)^2\;.
$$


#### Definition 1.4.6 : 확률분포의 표준화 (Standardization)

$X$ 의 평균이 $\mu$ 이고 표준편차가 $\sigma$ 일 때,
$$
Z=\dfrac{X-\mu}{\sigma}
$$
라 정의하면,
$$
\begin{align}
\mathbb{E}[Z]&=\dfrac{1}{\sigma} \mathbb{E}[X-\mu]=0\,,\\
\operatorname{Var}(Z)&=1 \;.

\end{align}
$$
임을 알 수 있다. 이 때 $Z$ 는 $X$ 를 표준화 한 변수라고 한다.



## 1.5 누적분포함수와 생성함수

