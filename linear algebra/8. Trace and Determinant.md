VIII. Trace and Determinant
===



#### Notation 

1. $\mathbb{F} = \mathbb{R}$ or $\mathbb{C}$.
2. $V$는 finite dimensional vector space.



## 1. Trace



#### Definition : Identity matrix

$n\times n$ 행렬 $I_n$ 이 $(I_n)_{i,\,j} = \delta_{i,\,j}$ for $1 \le i,\,j \le n$ 일 때 **identity matrix** 라 한다. 일반적인 identity matrix는 $I$로 표현한다.



#### Definition: Invertible matrix, Inverse matrix.

$n \times n$ 행렬 $A$에 대해 어떤 $n \times n$ 행렬 $B$가 존재하여 $AB=BA=I_n$ 일 때 $A$를 **invertible** 이라 하며 $B$를 **inverse** of $A$라 하고 $B=A^{-1}$ 로 쓴다.



#### Theorem 1.1

$\mathcal{B}_u=(u_1,\ldots,\,u_n)$, $\mathcal{B}_v=(v_1,\ldots,\,v_n)$, $\mathcal{B}_w=(w_1,\ldots,\,w_n)$ 이 각각 $V$의 basis 이고 $S,\,T\in \mathcal{L}(V)$ 일 때 다음이 성립한다.
$$
\begin{align*}
\mathcal{M}(ST,\,&\mathcal{B}_u,\,\mathcal{B}_v)  = \mathcal{M}(S,\,\mathcal{B}_w,\,\mathcal{B}_v)\mathcal{M}(T,\,\mathcal{B}_u,\,\mathcal{B}_w)\;.
\end{align*}
$$

---

*Proof is trivial*



#### Corollary 1.2

$\mathcal{B}_u=(u_1,\ldots,\,u_n)$, $\mathcal{B}_v=(v_1,\ldots,\,v_n)$ 이 $V$의 basis 일 때 $\mathcal{M}(I,\,\mathcal{B}_u,\,\mathcal{B}_v)$ 과 $\mathcal{M}(I,\,\mathcal{B}_v,\,\mathcal{B}_u)$ 는 invertible이며 각각 서로의 inverse 이다. 

---

*Proof is trivial from theorem 1.1*



#### Theorem 1.3

$T\in \mathcal{L}(V)$ 이고 $\mathcal{B}_u=(u_1,\ldots,\,u_n)$, $\mathcal{B}_v=(v_1,\ldots,\,v_n)$ 이 basis of $V$ 라 하자. $A=\mathcal{M}(I,\,\mathcal{B}_u,\,\mathcal{B}_v)$ 일 때 다음이 성립한다.
$$
\mathcal{M}(T,\,\mathcal{B}_u) = A^{-1}\mathcal{M}(T,\,\mathcal{B}_v)A\;.
$$

---

*(Proof)* 
$$
\begin{align*}
\mathcal{M}(T, \mathcal{B}_u,\,\mathcal{B_u}) &= \mathcal{M}(ITI,\,\mathcal{B}_u,\,\mathcal{B}_u) \\
&= \mathcal{M}(I,\,\mathcal{B}_v,\,\mathcal{B}_u)\mathcal{M}(T,\,\mathcal{B}_v,\,\mathcal{B}_v)\mathcal{M}(I,\,\mathcal{B}_u,\,\mathcal{B}_v)\\
&= A^{-1}\mathcal{M}(T,\,\mathcal{B}_v)A\;. \quad \square
\end{align*}
$$


#### Definition : Trace of an operator

$T\in \mathcal{L}(V)$라 하자. $V$가 complex vector space 일 때 **trace** of $T$ 는 multiplicity 까지 고려 한 $T$의 eigenvalues의 합이다. $V$가  real vector space 일 때 **trace** of $T$는 multiplicity 까지 고려 한 $T_C$의 eigenvalues의 합이다. Trace of $T$를 $\operatorname{tr} T$ 라 쓴다.



#### Theorem 1.4

$T\in \mathcal{L}(V)$ , $n = \dim V$ 일 때 $\operatorname{tr}T$ 는 $T$ (real vector space 인 경우는 $T_C$)의 characteristic polynomial $\chi_T(z)$ 의 $n-1$차 항의 계수에 $-1$을 곱한 값과 같다.

---

*(Proof)* Let $\lambda_1,\ldots,\,\lambda_n$ be eigenvalues of $T$( or $T_C$ ) including multiplicity. Then $\chi_T (z)  = \prod\limits_{i=1}^{n}(z-\lambda_i)$.  $n-1$ 차 항의 계수는 $- \sum\limits_{i=1}^n \lambda_i$.  $\square$ 



#### Definition : Trance of matrix

$A$가 $n \times n$ 행렬 일 때, **trace** of $A$는 $\operatorname{tr}A$ 라 하며 $\operatorname{tr}A= \sum\limits_{i=1}^n A_{ii}$ 로 정의된다.



#### Theorem 1.5

$A,\, B$가 같은 크기의 square matrix 일 때 $\operatorname{tr}(AB)=\operatorname{tr}(BA)$ 이다. 

---

*(Proof)* 
$$
\operatorname{tr}(AB) = {\textstyle \sum\limits_{i=1}^n (AB)_{ii}} = {\textstyle \sum\limits_{i=1}^n \sum\limits_{k=1}^n} A_{ik}B_{ki} = {\textstyle \sum\limits_{k=1}^n \sum\limits_{i=1}^n} B_{ki}A_{ik} = {\textstyle \sum\limits_{k=1}^n} (BA)_{kk} = \operatorname{tr}(BA) \;.\square
$$


#### Theorem 1.6

$\mathcal{B}_u = (u_1,\ldots,\,u_n)$, $\mathcal{B}_v=(v_1,\ldots,\,v_n)$ 이 $V$의 임의의 두 basis 일 때 $\operatorname{tr}(\mathcal{M}(T,\,\mathcal{B}_u))=\operatorname{tr}(\mathcal{M}(T,\,\mathcal{B}_v))$ 이다.

---

*(Proof)* Let  $A=\mathcal{M}(I,\,\mathcal{B}_u,\,\mathcal{B}_v)$. Then $\mathcal{M}(T,\,\mathcal{B}_u) = A^{-1}\mathcal{M}(T,\,\mathcal{B}_v)A$ from theorem 1.3. From theorem 1.5, 
$$
\operatorname{tr}(\mathcal{M}(T,\,\mathcal{B}_u))=\operatorname{tr}(A^{-1}\mathcal{M}(T,\,\mathcal{B}_v) A)=\operatorname{tr}(A^{-1}A\mathcal{M}(T,\,\mathcal{B}_v)) = \operatorname{tr}(\mathcal{M}(T,\,\mathcal{B}_v))\;.\square
$$
<b>Comment : </b> Operator 의 matrix form에 대한 trace가 basis-independent 하므로 $\operatorname{tr}(\mathcal{M}(T))$를 정의 할 수 있다. 



#### Theorem 1.7

$T\in\mathcal{L}(V)$ 일 때 $\operatorname{tr}T = \operatorname{tr}\mathcal{M}(T)$ 이다.

----

*Proof is trivial*



#### Lemma 1.8

$A,\,B$가 $n \times n$ matrix 일 때 $\operatorname{tr}(A+B) = \operatorname{tr}A+\operatorname{tr}B$ 이다.

---

*(Proof)* $\operatorname{tr}(A+B) = \sum\limits_{i=1}^n (A+B)_{ii} = \sum\limits_{i=1}^n (A_{ii} + B_{ii}) = \operatorname{tr}A + \operatorname{tr}B$. $\square$ 



#### Theorem 1.9

$S,\,T \in \mathcal{L}(V)$ 일 때 $\operatorname{tr}(S+T)=\operatorname{tr}S + \operatorname{tr}T$ 이다.

---

*(Proof)*
$$
\operatorname{tr}(S+T) = \operatorname{tr}(\mathcal{M}(S+T)) = \operatorname{tr}(\mathcal{M}(S) +\mathcal{M}(T)) = \operatorname{tr}(\mathcal{M}(S))+ \operatorname{tr}(M(T)) = \operatorname{tr}S + \operatorname{tr}T\;. \square
$$


#### Theorem 1.10

어떤 $S,\,T\in \mathcal{L}(V)$ 에 대해서도 $ST-TS=I$를 만족할 수 없다.

---

*(Proof)* Suppose $ST-TS=I$. $\operatorname{tr}(ST-TS) = 0 \ne \dim V =\operatorname{tr}I$. $\square$ 



#### Exercise (chap. 10. A)

---



<b>1. </b> $T\in \mathcal{L}(V)$ 이고 $\mathcal{B}=(v_1,\ldots,\, v_n)$ 이 $V$의 basis라 할 때 다음을 보이시오.
$$
T \text{ is invertible} \iff \mathcal{M}(T) \text{ is invertible}
$$

---

(1) $T$ is invertible $\implies$ $T^{-1}$ exists $\implies$ $I=\mathcal{M}(TT^{-1}) = \mathcal{M}(T)\mathcal{M}(T^{-1})$ $\implies \mathcal{M}(T)$ is invertible.

(2) $\mathcal{M}(T)$ is invertible $\implies \mathcal{M}(T)A=A\mathcal{M}(T)=I$ for some $n\times n$ matrix $A$. $\implies$ $A$ is an matrix representation of some $S\in \mathcal{L}(V)$ and $ST=TS=I$ $\implies T$ is invertible.



<b>2. </b>  $A,\,B$가 같은 크기의 square matrix 일 때 $AB=I$ 이면 $BA=I$ 임을 보이시오.

---

$AB=I$ 이므로 $A,\,B$는 모두 invertible 이다. $B(AB)=B$ , $I=(BAB)B^{-1}=BA(BB^{-1})=BA$. 



<b>3. </b> $T\in \mathcal{L}(V)$ 이 모든 basis에서 같은 form을 가진다면 $T$는 $cI$ for some $c\in \mathbb{F}$ form 임을 보이시오.

---

(1) Let $n=\dim V$. $u\in V$에 대해 $u$와 $Tu$가 linearly dependent 함을 보이자. $u$와 $Tu$가 linearly independent 하다면 $(u,\,Tu,\,u_1,\ldots,\,u_{n-2})$ 인 basis of $V$가 존재한다. 이 basis에서의 Matrix form 의 첫번째 column은 $[0\quad 1 \quad \cdots \quad]^T$ 이다. 또한 $(2u,\,Tu,\,u_1,\ldots,\,u_{n-2})$ 도 basis of $V$ 이며 이 basis 에서의 matrix form의 첫번째 column은 $[0\quad 1/2 \quad \cdots \quad]^T$ 이므로 문제의 조건에 위배. 따라서 $u$와 $Tu$는 linearly dependent 하다. 이로부터 모든 $u\in V$는 $Tu = c_u u$ for some $c_u\in \mathbb{F}$ 이므로 모든 $u\in V$는 eigenvectors of $T$ 이다.

(2) $\mathcal{B}=(u_1,\ldots,\,u_n)$ 이 basis of $V$ 일 때 $\mathcal{M}(T,\,\mathcal{B})$ 는 diagonal 하다. 만약 $Tu_i = c_i u_i$ 일 때 $c_i \ne c_j$ 라 하자. $\mathcal{B}$ 에서 $u_i \longleftrightarrow u_j$ 한 것을 $\mathcal{B}'$ 이라 하면 $\mathcal{M}(T,\,\mathcal{B}')\ne \mathcal{M} (T,\,\mathcal{B})$ 이다. 따라서 $Tu_i = c u_i$ 이므로 $T=cI$ 꼴이다.



<b>4. </b> $\mathcal{B}_u = (u_1,\ldots,\,u_n)$, $\mathcal{B}_v = (v_1,\ldots,\,v_n)$ 이 각각 basis of $V$ 라 하자. $T\in \mathcal{L}(V)$ 가 $Tv_k=u_k$ for $k=1,\ldots,\,n$ 을 만족시킨 다면 다음을 보이시오.
$$
\mathcal{M}(T,\,\mathcal{B}_v) = \mathcal{M}(I,\,\mathcal{B}_u,\,\mathcal{B}_v)\;.
$$

---

$Tv_k = u_i$ 로부터 $\mathcal{M}(T,\,\mathcal{B}_v,\,\mathcal{B}_u)=I$ 임을 알 수 있다. 
$$
\begin{align*}
\mathcal{M}(T,\,\mathcal{B}_v) & = \mathcal{M}(T,\,\mathcal{B}_v,\,\mathcal{B}_v) \\
&= \mathcal{M}(I, \mathcal{B}_u,\,\mathcal{B_v})\mathcal{M}(T,\,\mathcal{B}_v,\,\mathcal{B}_u) & \quad ;\text{Theorem 1.3}\\
&= M(I,\,\mathcal{B_u},\,\mathcal{B}_v) I =  M(I,\,\mathcal{B_u},\,\mathcal{B}_v)
\end{align*}
$$
<b>5. </b> $B$가 complex entries를 가지는 square matrix라 하자. 그렇다면 $A^{-1}BA$가 upper triangular form이 되도록 하는 square complex matrix $A$가 존재함을 보이시오.

---

(1) Let $B$ be a $n\times n$ matrix and consider $\mathbb{C}^n$. Let $(e_1,\ldots,\,e_n)$ be standard basis of $\mathbb{C}^n$. Define $T\in \mathcal{L}(\mathbb{C}^n)$ by $Te_i = \sum\limits_{j=1}^n B_{ji}e_j$. $T$는 어떤 basis of $\mathbb{C}^n$ $(f_1,\ldots,\,f_n)$ 에서 upper triangular form 을 가진다. 즉 $Tf_i \in \operatorname{span}(f_1,\ldots,\,f_i)$ 

(2) Define $S\in \mathcal{L}(\mathbb{C}^n)$ by $Se_i = f_i$ for $i=1,\ldots,\,n$. Then $S$ is invertible.

(3) $S^{-1}TSe_i  =S^{-1}Tf_i \in \operatorname{span}(e_1,\ldots,\,e_i)$. 따라서 $A =\mathcal{M}(S,\,(e_1,\ldots,\,e_n),\,(f_1,\ldots,\,f_n))$. 



<b>6. </b> $V$가 real vector space 이고 $T\in \mathcal{L}(V)$ 일 때 $\operatorname{tr} (T^2)<0$ 인 예를 드시오.

---

Let $V=\mathbb{R}^2$ and define $T\in \mathcal{L}(V)$ be $Te_1=e_1-e_2$ and $Te_2= 2e_1+e_2$ for $(e_1,\,e_2)$ are basis of $V$. Then, 
$$
\begin{align*}
T^2e_1 &= T(e_1-e_2) = e_1-e_2 -2e_2-e_2 = -e_1-2e_2\;.\\
T^2e_2 &= T(2e_1+e_2) = 2e_1-2e_2 + 2e_1 +e_2 = 4e_1 -e_2\;.
\end{align*}
$$
$\operatorname{tr}(T^2)= -2-1=-3<0$. 



<b>7. </b> $V$가 real vector space 이고 $T\in \mathcal{L}(V)$ 이며 $V$가 eigenvectors of $T$로 이루어진 basis가 존재 할 때 $\operatorname{tr}T^2 \ge0$ 임을 보이시오.

---

Trace는 basis independent 하다. Let $(e_1,\ldots,\,e_n)$ be a basis of $V$ and eigenvectors of $T$. Then $Te_i = \lambda_i e_i$ for $\lambda_i \in \mathbb{R}$ . $T^2e_i = {\lambda_i}^2 e_i$. $\operatorname{tr}(T^2)= \sum\limits_{i} {\lambda_i}^2 \ge 0$. 



<b>8. </b> $V$가 inner product space 이고 $v,\,w\in V$ 에 대해 $T\in \mathcal{L}(V)$는 $Tu = \langle v|u\rangle w$ 로 정의된다고 하자. $\operatorname{tr}T$ 를 구하시오.

---

Let $e_1,\ldots,\,e_n$ be orthonormal basis of $V$. Then $v=\sum_i a_i e_i$ and $w=\sum_j b_j e_j$. 
$$
Te_i = \sum_j \langle v|e_i\rangle b_j e_j = \sum_j \overline{a_i} b_je_j\;.
$$
Then $\operatorname{tr}T = \sum_j \overline{a_j} b_j = \langle v|w\rangle$. 



<b>9. </b> $P \in \mathcal{L}(V)$ 가 $P^2 = P$ 이면 $\operatorname{tr}P = \dim \operatorname{range}P$ 임을 보이시오.

---

Let $u \in \ker P \cap \operatorname{range}P$. $Pu=0$ and $u=Pv$ some $v\in V$. $0=Pu = P^2v = Pv = u $ 따라서 $\ker P \cap \operatorname{range}P =\{0\}$ and $V=\ker P \oplus \operatorname{range}P$. 

Let $u_1,\ldots,\,u_n$ be a basis of $\ker P$ and $v_1,\ldots,\,v_m$ be a basis of $\operatorname{range}P$. $v_i = Pv$ for some $v\in V$  and $Pv_i = v_i$.  또한 $Pu_i = 0$. 따라서 $\operatorname{tr} P = \dim \operatorname{range}P$.



<b>10. </b> $V$가 inner product space 이고 $T\in \mathcal{L}(V)$ 일 때 $\operatorname{tr}T^{\dagger} = \overline{\operatorname{tr}T}$ 임을 보이시오.

---

Let $u_1,\ldots,\,u_n$ be a basis of $V$. 
$$
\operatorname{tr}T^\dagger = \sum_i^n \langle u_i|T^\dagger u_i\rangle = \sum_i^n \langle Tu_i |u_i\rangle = \sum_i^n \overline{\langle u_i |Tu_i \rangle} = \overline{\operatorname{tr}T}\;.
$$


<b>11.</b> $V$가 inner product space 이고 $T\in \mathcal{L}(V)$ 가 positive operator 이며 $\operatorname{tr}T = 0$ 이면 $T=0$ 임을 보이시오.

---

Let $u_1,\ldots,\,u_n$ be a basis of $V$. $T$가 positive 이므로 $\langle u_i |Tu_i\rangle = \mu _i\ge 0$ for $i=1,\ldots,\,n$. 

$\operatorname{tr}T =0 \implies \sum\limits_i \langle u_i |Tu_i \rangle =0$. 따라서 모든 $i=1,\ldots,\,n$ 에 대해 $\mu_i=0$. 

$T$가 positive 이면 hermitian 이므로 어떤 basis 에서 diagonal 한데 앞의 조건에 의해 모든 diagonal elements 가 0 이므로 $T=0$.



<b>12. </b> $V$가 inner product space 이고 $P,\,Q \in \mathcal{L}(V)$가 orthogonal projections 일 때 $\operatorname{tr}(PQ)\ge 0$ 임을 보이시오.

---

$P,\,Q$가 orthogonal projection 이므로 어떤 $V$의 subspaces $U_1,\,U_2$와 $(U_1)^\perp,\, (U_2)^\perp$ 에 대해, $v=V$는 $v=u_1+ w_1$ where $u_1\in U_1, \, w_1 \in (U_1)^\perp$, $Pv=u_1$ 이며 $v=u_2+w_2$ where $u_2 = U_2, \,  w_2 = (U_2)^\perp$, $Qv=u_2$ 이다.

$v \not\in U_1 \cap U_2$ 이면 $PQv=0$ 이다. 따라서 $U=U_1\cap U_2$, 라 하면 $U$는 subspace of $V$ 이며 $PQu=u$ for all $u \in U$, and $PQw=0$ for all $w \in U^\perp$. 즉 $PQ$도 orthogonal projection 이다. exercise  9에 의해 $\operatorname{tr}(PQ) = \dim \operatorname{range}(PQ)\ge 0$. 



<b>13. </b> $T\in \mathcal{L}(\mathbb{C}^3)$ 의 matrix form은 다음과 같다.
$$
\begin{bmatrix} 51 &-12 & -21 \\ 60 & -40 & -28 \\57 & -68 & 1
\end{bmatrix}
$$
만약 $-48$과 $24$가 eigenvalue of $T$라는 것을 안다면 다른 하나의 eigenvalue는 무엇인가?

---

trance of operator = sum of eigenvalues. 따라서 $51-40+1=-48+24+x$ . $x=36$. 



<b>14. </b> $T\in \mathcal{L}(V)$ 이고  $c\in \mathbb{F}$ 일 때, $\operatorname{tr}(cT) = c\operatorname{tr}T$ 임을 보이시오.

---

Let $u_1,\ldots,\,u_n$ be a basis of $V$. $Tv_i = \sum_j a_{ji}v_j$ 일 때 $\operatorname{tr}T=\sum_j a_{jj}$ 이다. $\operatorname{tr}(cT) = c(\sum_j a_{jj}) = c \operatorname{tr}T$. 



<b>15. </b> $S,\,T \in \mathcal{L}(V)$ 일 때 $\operatorname{tr}(ST) = \operatorname{tr}(TS)$ 임을 보이시오.

---

Let $u_1,\ldots,\,u_n$ be a basis of $V$. $Sv_i = \sum_j a_{ji}v_j$ and $Tv_i = \sum_j b_{ji}v_j$ 라 하자. $STv_i = \sum_j b_{ji}Sv_j = \sum_j \sum_k b_{ji}a_{kj}v_k$ , $TSv_i =\sum_j a_{ji}Tv_j = \sum_j \sum_k a_{ji}b_{kj}v_k$. 따라서, 
$$
\operatorname{tr}(ST) = \sum_i\sum_j b_{ji}a_{ij}, \quad \quad \operatorname{tr}(TS)= \sum_i\sum_j a_{ji}b_{ij}
$$
이므로 $\operatorname{tr}(ST)= \operatorname{tr}(TS)$ 이다.



<b>16. </b> $S,\,T \in \mathcal{L}(V)$ 일 때 $\operatorname{tr}(ST)$ 는 $(\operatorname{tr}S) (\operatorname{tr}T)$ 와 같은가 다른가? 같다면 증명하고 다르다면 예를 드시오.

---

Let $V=\mathbb{R}^2$ ,  $S=\begin{bmatrix}1 & 0 \\ 0 & 0\end{bmatrix}$ and $T=\begin{bmatrix}0 & 0 \\ 0 & -1\end{bmatrix}$. $ST=\begin{bmatrix} 0 & 0 \\ 0 & 0 \end{bmatrix}$. $\operatorname{tr}(ST) = 0$ but $(\operatorname{tr}S)(\operatorname{tr}T) =-1$.



<b>17. </b> $T\in \mathcal{L}(V)$가 모든 $S\in\mathcal{L}(V)$에 대해 $\operatorname{tr}(ST)=0$ 이라면 $T=0$ 임을 보이시오.

---

Let $(e_1,\ldots,\,e_n)$ be a basis of $V$ and $Te_i = \sum_j a_{ji}e_j$. Define $S\in \mathcal{L}(V)$ by $Se_i = \sum_j b_{ji}e_j$ with $b_{ji} = \overline{a_{ij}}$.  Then, $STe_i = \sum_j a_{ji}Se_j = \sum_j\sum_k a_{ji}b_{kj}e_k = \sum_j \sum_k a_{ji}\overline{a_{jk}}e_k$ .
$$
\operatorname{tr}(ST) = \sum_i \left( \sum_j a_{ji}\overline{a_{ji}}\right)=\sum_i \sum_j|a_{ji}|^2=0
$$
따라서 $a_{ji}=0$ for all $1 \le i,\,j \le \dim V$ 이므로 $T=0$. 



<b>18. </b> $V$가 inner product space 이고 $e_1,\ldots,\,e_n$ 이 orthonormal basis of $V$ 이며 $T\in \mathcal{L}(V)$ 일 때 다음을 보이시오.
$$
\operatorname{tr}(T^\dagger T) = \|Te_1\|^2 + \cdots +\|Te_n\|^2\;.
$$
 위 식의 우변이  $V$의 orthonormal basis의 선택에 independent 함을 보이시오.

---

(1) Let $Te_i= \sum_j a_{ji}e_j$. Then $T^\dagger e_i= \sum_j \overline{a_{ij}} e_j$ and $T^\dagger T e_i = \sum_j \sum_k \overline{a_{ij}}a_{kj}e_k$ . 

(2) $\|Te_j\|^2 = \langle Te_j |Te_j\rangle = \langle e_j |T^\dagger Te_j\rangle = \sum_i |a_{ij}|^2$. 

(3) 따라서 $\operatorname{tr}(T^\dagger T) = \sum_i \left( \sum_j \overline{a_{ij}} a_{ij} \right) = \sum_i \sum_j \|a_{ij}\|^2 = \sum_j \|T e_j\|^2$. 

(4) 원래 trace 는 basis independent.



<b>19. </b> $V$가 inner product space 일 때 $\langle T|S\rangle = \operatorname{tr}(ST^\dagger)$ 는 $\mathcal{L}(V)$에서의 inner product  임을 보이시오.

---

(1) $\langle T|T \rangle = tr(TT^\dagger) \ge 0$ ; see exercise 18.

(2) $\langle T|T\rangle =0 \implies T=0$  ; see exercise 18.

(3) Let $S_1,\,S_2 \in \mathcal{L}(V)$. Then, 

$$
\begin{align*}
\langle T|S_1+S_2\rangle &= \operatorname{tr} ((S_1+S_2)T^\dagger) = \operatorname{tr}(S_1 T^\dagger + S_2 T^\dagger) \\
&= \operatorname{tr}(S_1 T^\dagger)+ \operatorname{tr}(S_2T^\dagger) \\&= \langle T|S_1\rangle + \langle T|S_2\rangle
\end{align*}
$$

(4) Let $\lambda\in \mathbb{F}$. $\langle T|\lambda S\rangle = \operatorname{tr}(\lambda ST^\dagger) = \lambda \operatorname{tr})(ST^\dagger )= \lambda \langle T|S\rangle$. 

(5) $\langle S|T\rangle = \operatorname{tr}(TS^\dagger)=\operatorname{tr}((ST^\dagger)^\dagger) = \overline{\operatorname{tr}(ST^\dagger)} = \overline{\langle T|S\rangle}$. 



<b>20. </b> $V$가 complex inner product space 이고 $T\in \mathcal{L}(V)$ 이다. $\lambda_1,\ldots,\,\lambda_n$이 $T$의 multiplicities를 포함한 eigenvalues 이고 $A$는 $V$의 어떤 orthonormal basis $e_1,\ldots,\,e_n$에서의 matrix form 이다. 다음을 보이시오.
$$
\sum_{i=1}^n |\lambda_i|^2 \le \sum_{k=1}^n \sum_{j=1}^n |A_{j,\,k}|^2\;.
$$

---

Trace is basis independent. 따라서,
$$
\sum_{i=1}^n |\lambda_i|^2 = \sum_{j=1}^n |A_{j,j}|^2 \le \sum_{k=1}^n \sum_{j=1}^n |A_{j,\,k}|^2\;. 
$$


<b>21. </b> $V$가 inner product space 이고 $T\in \mathcal{L}(V)$ 이며 $\|T^\dagger v\|\le \|Tv\|$ for every $v\in V$ 라 하자. $T$가 normal 임을 보이시오.

---

(1) $\langle v|(T^\dagger T - TT^\dagger)v\rangle = \langle v|T^\dagger Tv\rangle - \langle v|TT^\dagger v\rangle = \|Tv\|^2-\|T^\dagger v\|^2 \ge 0$ for any $v\in V$.  따라서 $T^\dagger T - TT^\dagger$는 positive operator 이다. 

(2) $\operatorname{tr}(T^\dagger T-TT^\dagger) = 0$.  exercise 11에 의해 $T^\dagger T-TT^\dagger = 0$. 즉 $T$는 normal operator.



## 2. Determinant



#### Definition

$T\in \mathcal{L}(V)$ 라 하자.

1. $\mathbb{F}=\mathbb{C}$ 일 때 $T$의 multiplicity까지 고려한 eigenvalues 를 $\lambda_1,\ldots,\,\lambda_n$ 이라 하자. **determinant** of $T$는 $\prod_{i=1}^n \lambda_i$ 이다.
2. $\mathbb{F}=\mathbb{R}$ 일 때 $T_C$의 multiplicity까지 고려한 eigenvalues 를 $\lambda_1,\ldots,\,\lambda_n$ 이라 하자. **determinant** of $T$는 $\prod_{i=1}^n \lambda_i$ 이다.

**determinant** of $T$는 $\det T$ 라 쓴다.



#### Theorem 2.1

$T\in \mathcal{L}(V)$ 이고 $n =\dim V$라 하자. $\chi_T (z)$를 characteristic polynomial of $T$라 하면 $\det T = (-1)^n \chi_T (0)$  이다. 

---

*(Proof)* $\chi_T (z) = \prod_{i=1}^n (z-\lambda_i) = z^n + \cdots + (-1)^n \prod_{i=1}^n \lambda_i = z^b + \cdots +  (-1)^n (\det T) $. $\square$



#### Theorem 2.2

$T\in \mathcal{L}(V)$ 일 때 다음이 성립한다.
$$
T \text{ is invertible} \iff \det T \ne 0\;.
$$

---

*(Proof)* (1) Suppose $V$ is complex vector space. $T$ is invertible $\iff$ $0$ is not an eigenvalue of $T \iff \det T \ne 0$. 

(2) Suppose $V$ is real vector space. $T$ is invertible $\iff$ $0$ is not an eigenvalue of $T$ $\iff$ $0$ is not an eigenvalue of $T_C$ $\iff$ $\det T\ne 0$. $\square$ 



#### Theorem 2.3

$T\in \mathcal{L}(V)$ 이고 characteristic polynomial of $T$를 $\chi_T(z)$라 하면 $\chi_T (z) = \det (zI-T)$ 이다.

---

*(Proof)* (1) $T$가 complex vector space라 하자. $\lambda,\,z\in \mathbb{C}$에 대해, $\lambda$ is an eigenvalue of $T \iff (z-\lambda)$ is an eigenvalue of $zI-T$. 따라서 multiplicity of $\lambda$ in $T$ = multiplicity of $(z-\lambda)$ in $(zI-T)$. 

(2) $\lambda_1,\ldots,\,\lambda_n$ 이 multiplicity를 포함하는 eigenvalues of $T$ 이면 $z-\lambda_1,\ldots,\,z-\lambda_n$ 은 multiplicities를 고려한 eigenvalues of $zI-T$ 이다. 따라서
$$
\det (zI-T) = \prod_{i=1}^n (z-\lambda_i) = \chi_T (z)\;. \quad \square
$$



#### Definition : Permutation , $\operatorname{perm} n$. 

**permutation** of $n$은 $(m_1,\ldots,\,m_n)$ where $1\le m_i \le n$ 이며 $m_i \ne m_j$ if $i\ne j$ 인 list 이다. $\operatorname{perm} n$ 은 모든 permutation of $n$ 의 집합이다. 이와 동등하게 혹은 $(1,\ldots,\,n) \to (1,\ldots,\, n)$ 인 모든 bijective functions 의 집합으로 정의할 수 있다. $\sigma \in \operatorname{perm} n$ 일 때 다음과 같이 표현 할 수 있다.
$$
\sigma = \begin{pmatrix} 1 & 2 &\cdots & n-1  & n \\ \sigma(1) & \sigma(2) & \cdots & \sigma (n-1) & \sigma (n)\end{pmatrix}\;.
$$



#### Definition : Product of permutation, Cyclic notation of a permutation

$\sigma \in \operatorname{perm}(3)$, $\sigma = \begin{pmatrix} 1 & 2 & 3 \\ 2 & 3 & 1 \end{pmatrix}$ 라 하자. $\sigma(1)=2$, $\sigma \circ \sigma (1) = \sigma(2) = 3$, $\sigma \circ \sigma \circ \sigma(1) = \sigma (3)=1$ 이며 이것을 $(x,\, \sigma (x), \sigma^2 (x), \cdots,\, \sigma^k(x))$ where $k$ is the smallest positive integer s.t. $\sigma^k=x$ 개념으로 $(1,\,2,\,3)$ 으로 쓸 수 있다. 이렇게 표현하는 것을 **cyclic notation** of a permutation 이라 한다. $(1,\,2,\,3)= (2,\,3,\,1)= (3,\,1,\,2)$ 임은 쉽게 알 수 있다.

$\sigma_1,\, \sigma_2\in \operatorname{perm} (n)$ 라면 $\sigma_1 \circ \sigma_2 \in \operatorname{perm} (n)$ 임은 자명하다. 이 때 $\sigma_1 \circ \sigma_2$를 **product of permutation** 이라 한다.  

$\sigma = (1,\,2)(2,\,3)$ 이라 하자. 이것을 $1\to 2 \to 3$, $2\to 1$ $3 \to 2$ 로 왼쪽의 cycle 부터 읽어가며 이해할 수 도 있고 $3\to 2 \to 1$, $2\to 3$, $1 \to 2$로 오른쪽의 cycle 부터 읽어가며 이해할 수도 있다. 이것은 convention 문제로 여기서는 오른쪽부터 읽어가는 것으로 하자.  

$\sigma \in \operatorname{perm}(6)$, $\sigma = \begin{pmatrix} 1 & 2 & 3 & 4 & 5 & 6 \\ 3 & 6 & 4 & 1 & 5 & 2 \end{pmatrix}$ 라 하자. $\sigma(1) = 3$, $\sigma(3)=4$, $\sigma(4) = 1$, $\sigma (2)=6$, $\sigma (6)= 2$,  $\sigma(5) = 5$ 이다. 이를 $\sigma = (1,\,3,\,4)(2,\,6)(5)$ 라 쓸 수 있으며 $(5)$와 같이 각각의 순회하는 $( \cdots )$ 를 cycle 이라 한다.   $n$개의 원소로 구성된 cycle을 $n$-cycle 이라 하며 , $1$-cycle의 경우 permutation에 포함된것이 명백하다면 표기하지 않을 수 있다. 

이렇게 permutation을  서로 교집합이 없는  cycles의 product로 표현하는 것을 **cyclic decomposition** 이라 한다. 

우선 임의의 $n$-cycle은  $2$-cycles의 product로 표현 될 수 있다. $\sigma=(a_1,\, a_2,\ldots,\, a_n)$ 일 경우, 
$$
\sigma = (a_1,\ldots,\,a_n) = (a_1,\,a_2)(a_2,\,a_3)\cdots (a_{n-1},\,a_n)
$$
이다. 다만 이런 $2$-cycles의 product로 표현하는 것은 unique 하지 않다. 예를 들어 $(1,\,2,\,3) = (1,\,2)(2,\,3)$ 이기도 하지만 $(1,\,2,\,3)= (1,\,3)(1,\,2)$ 이기도 하다. 그러나 cyclic decomposition의 경우는 cycles의 순서와 각 cycle의 동등한 표현을 고려하면 unique 하다.



#### Example 1.

$V$가 $n$-dim vector space 이고 $T\in \mathcal{L}(V)$라 하자. $V$의 어떤 basis $(v_1,\ldots,\,v_n)$ 에서 $T$가 $Tv_i = a_i v_{i+1}$ for $i=1,\ldots,\,n-1$ and $Tv_n = a_n v_1$ 이라 하자. $A_0=\mathcal{M}(T,\,(v_1,\ldots,\,v_n))$ 이라 하면,
$$
A_0=\begin{bmatrix} 
0 & & & & a_{n} \\ a_{1} &  & & & 0 \\ 0 &a_{2} & 0 & & 0 \\ & & \ddots &\ddots \\& & & a_{n-1}& 0 
\end{bmatrix} \quad \quad \quad (*)
$$
 이다. 이 때 $T^n v_i = a_1a_2 \cdots a_n v_i$이므로 $(T^n - (a_1 \cdots a_n) I)=0$ 이다. $\chi (z) = z^n - (a_1\cdots a_n)$ 이라 하면 $\chi$는 characteristic polynomial of $T$ 임은 자명하다. 따라서 theorem 2.1에 의해 
$$
\det T = -(-1)^n(a_1\cdots a_n) = (-1)^{n-1}(a_1 \cdots a_n)
$$

이다. 



#### Example 2.

Let $V$ is an $n$-dim vector space, $\mathcal{B}_0=(v_1,\ldots,\,v_n)$ be a basis of $V$,  and  $\sigma \in \operatorname{perm}(n)$. Let $\sigma (k) = p_k$. $T\in \mathcal{L}(V)$ 가 $Tv_k = a_k v_{p_k}$ for $k=1,\ldots,\,n$ 이라 하자. $\sigma$의 cyclic decomposition을 생각하자. $(k_1,\,\ldots,\,k_m)$ 이 $\sigma$의 cyclic decomposition의 일부라면 $U_0=\operatorname{span}(v_{k_1},\ldots,\,v_{k_m})$ 은 invariant subspace of $V$ for $T$ 이며 proper subspace of $U_0$는 존재하지 않는다. $\sigma$ 의 cyclic decomposition components에 따라 $V$를 invariant subspace of $V$의 direct sum 으로 표현 할 수 있다. $\sigma$가 $M$개의 cycles로 decomposition 된다면 $V=V_1 \oplus \cdots \oplus V_M$ 이다. 

Cycle $(k_1,\ldots,\,k_m)$ 에 의한 subspace가 $V_i$라 하자. 그렇다면 $(v_{k_1},\ldots,\,v_{k_m})$ 이 $V_i$의 basis 이며 $Tv_{k_i}=a_{k_i}v_{k_{i+2}}$ for $i<m$ 이며 $Tv_{k_m} = a_{k_m}v_{k_1}$ 이다. 이것의 matrix form $A_i=\mathcal{M}(T|_{V_i},\, (v_{k_1},\ldots,\,v_{k_m}))$은 당연히 example 1의 $A_0$와 같은 form이 되며 $n_i=\dim V_i$ 라 하면 $\det (T|_{V_i}) = (-1)^{n_i -1}a_{k_1}\cdots a_{k_m}$  이다. 

 $\mathcal{B}_0$의 basis의 순서 위에서처럼 cyclic decomposition에 따라 를 바꾸어 $T$를  행렬로 표현한 것을 $A$라 하면 $A$는 당연히 아래와 같은 block diagonal form이 된다.
$$
A=\begin{bmatrix} A_1 & & 0 \\ & \ddots & \\ 0 & & A_M\end{bmatrix} \;.
$$
Determinant는 multiplicity를 고려한 eigenvalues의 곱이므로 $\det A = \det A_1 \times \cdots \times \det A_M$ 이다. 따라서,
$$
\det T = (-1)^{n_1-1}\cdots (-1)^{n_M -1}a_1 \cdots a_n = (-1)^{n-M}a_1 \cdots a_n
$$
이다. 

여기서 $(-1)^{n-M}$ 은 permutation $\sigma$에 의존하는 값이며 이를 $\operatorname{sgn} (\sigma)$ 라 한다. 즉 $\sigma \in \operatorname{perm}(n)$  일 때 $\sigma$가 $M$개의 cycles로 decomposition 되될 때 (이 $M$값은 unique 하다.) $\operatorname{sgn}(\sigma)= (-1)^{n-M}$ 으로 정의된다.



$B=\mathcal{M}(T,\,\mathcal{B}_0)$ 는 다음과 같다는 것을 보일 수 있다.
$$
B_{j,\,k} = \left\{\begin{array}{ll}0 \quad \quad& \text{if } j \ne p_k\; ; \\a_k & \text{if } j= p_k \;.  \end{array}\right.
$$
$\det B=\det A$  이어야 하므로, 
$$
\det B = \sum_{\mu \in \operatorname{perm}(n)} \operatorname{sgn}(\mu)B_{\mu (1),\,1} \cdots B_{\mu(n),\,n}
$$
이다. $B$ 의 정의에 의해 $\mu \ne \sigma$ 이면 최소한 하나의 $B_{\mu(j),\,j}$는 $0$이므로 $\det B= \det A$ 이다. 



#### Properties of $\operatorname{sgn}$ function

$\operatorname{sgn}: \operatorname{perm} (n) \to \{-1,\,1\}$ 을 생각하자. $\sigma \in \operatorname{perm}(n)$ 이고  $\sigma$의 cyclic decomposition 시 component의 갯수가 $m$개 일 때 $\operatorname{sgn}(\sigma)= (-1)^{n-m}$ 으로 정의된다. cyclic decomposition시 composition의 갯수와 각 component의 elements의 갯수는 unique 하므로 $\operatorname{sgn}(\sigma)$ 는 잘 정의된 함수이다. 여기서 $\operatorname{sgn}$ 의 성질을 알아보자. 

<b>1. </b> 앞서 보았듯이 $k$-cycle은 $(k-1)$ 개의 $2$-cycle의 product로 표현 할 수 있다. 예를들어 $(a_1,\ldots,\,a_k) = (a_1,\,a_2)\cdots (a_{k-1},\,a_k)$ 이다.$\sigma \in \operatorname{perm}(n)$의 cyclic decomposition 이 $M$개의 $k$-cycle로 구성되어 있으며 각 elements가 $n_1, \ldots,\,n_M$ 개 이면 $\sigma$는 $n-M$개의 $2$-cycles의 product 이다. 즉, 이렇게 만들어진 $2$-cycles의 갯수를 $n(\sigma)$ 라 하면 $n(\sigma)= n-M$ 이며,

$$
\operatorname{sgn}(\sigma) = \prod\limits_{i=1}^M (-1)^{n_i-1}=(-1)^{n(\sigma)}
$$

이다. 

그런데 우리는 $\sigma$를 $2$-cycles의 product로 표현하는 것이 유일하지 않음을 알고 있다. $(1,\,2,\,3)= (1,\,2)(2,\,3)$ 일 뿐만 아니라 $(1,\,2,\,3)= (1,\,2)(2,\,3)(1,\,2)(1,\,2)$ 이다. 

<b>2. </b> 만약 $\sigma \in \operatorname{perm}(n)$ 이 일단  짝수개의 $2$-cycles의 product로 표현된다면  $\sigma$를 어떠한 다른 숫자와 종류의 $2$-cycles의 product로 표현해도 짝수개의 $2$-cycles의 product로 밖에 표현 할 수 없다는 것, 그리고 홀수도 마찬가지라는 것을 증명하자. $\sigma$가 짝수개의 $2$-cycles의 product로 표현된다면 even parity, 홀수개의 $2$-cycles의 product로 표현된다면 odd parity를 가진다고 말한다. 이는 주어진 문제가 $\sigma$의 parity 는 어떤 representation에 대해서도 보존됨을 보이라는 것과 마찬가지 이다. 

$\sigma=(a^1_1,\ldots,\,a^1_{n_1})\cdots (a^M_1,\ldots,\,a^M_{n_M})$ 로 cyclic decomposition 된다고 하자.  $\sigma_1 = (b,\,c)$ 일 때 $\operatorname{sgn}(\sigma_1\sigma) = \operatorname{sgn}(\sigma \sigma_1)= -\operatorname{sgn}(\sigma)$ 임을 보이자. $b,\,c$가 $\sigma$의 어떤 component cycle에도 포함되지 않는다면 자명하다. $b$가 포함되고 $c$가 포함되지 않는다고 하자. $b=a^k_j$ 일 때 
$$
(b,\,c)(b=a^k_j,\,a^k_{j+1},\cdots,\,a^k_{n_k},\,a^k_1,\ldots,\,a^k_{j-1})=(c,\,b=a^k_{j},\,a^k_{j+1},\ldots,\,a^k_{n_k},\,a^k_1,\ldots,\,a^k_{j-1})
$$

이므로 $\operatorname{sgn}(\sigma_1 \sigma) = -\operatorname{sgn}(\sigma)$가 성립한다. $c$가 포함되고 $b$가 포함되지 않아도 마찬가지이다.

$(b,\,c)$ 가 하나의 component cycle $(b=a^k_1,\,\ldots,\,c=a^k_{m},\ldots,\,a^k_{n_k})$ 에 포함된다고 하면 
$$
(b,\,c)(b=a^k_1,\,\ldots,\,c=a^k_{m},\ldots,\,a^k_{n_k}) = (b=a^k_1,\ldots,a^k_{m-1})(c=a^k_{m},\ldots,\,a^k_{n_k})
$$
이며 역시 $\operatorname{sgn}(\sigma_1 \sigma) = -\operatorname{sgn}(\sigma)$가 성립한다.

$(b,\,c)$ 가 각각 서로 다른 cycle $(b=a^k_1,\ldots,\,a^k_{n_k})$, $(c=a^p_1,\ldots,\,a^p_{n_p})$ 에 포함된다고 하자. 
$$
(b,\,c)(b=a^k_1,\ldots,\,a^k_{n_k})(c=a^p_1,\ldots,\,a^p_{n_p}) = (b=a^k_1 ,\ldots,\,a^k_{n_k},\,c=a^p_1,\ldots,\,a^p_{n_p})
$$
이므로 $\operatorname{sgn}(\sigma_1 \sigma) = -\operatorname{sgn}(\sigma)$가 성립한다. 같은 방법으로 $\operatorname{sgn}(\sigma \sigma_1)= -\operatorname{sgn}(\sigma)$ 임을 보일 수 있다. Cyclic decomposition의 유일성으로부터 $\sigma \in \operatorname{perm}(n)$ 의 parity가 유일하게 정해진다는 것을 의미한다. 

$\sigma_1,\,\sigma_2 \in \operatorname{perm}(n)$ 일 때 $\operatorname{sgn}(\sigma_1 \sigma_2) = \operatorname{sgn}(\sigma_1)\operatorname{sgn}(\sigma_2)$ 임은 위로부터 자연스럽게 도출된다.



#### Theorem 2.4

$\sigma \in \operatorname{perm}(n)$ 일 때 $1\le i,\,j\le n$ 에 대해 $\sigma'\in \operatorname{perm}(n)$ 을 다음과 같이 정의하자.
$$
\sigma'(k) = \left\{\begin{array}{ll} \sigma(j) \quad\quad &\text{if }k = i; \\ \sigma(i) & \text{if } k = j; \\ \sigma (k) & \text{otherwise}.\end{array} \right. 
$$
그렇다면 $\operatorname{sgn}(\sigma')= -\operatorname{sgn}(\sigma)$ 이다.

---

*(proof)* $\sigma ' = \sigma \circ (i,\,j)$.  $\square$.



#### Definition : Determinant of a matrix

$A$가 $n \times n$ 행렬 일 때, **determinant** of $A$는 다음과 같이 정의된다.
$$
\det A = \sum_{\sigma \in \operatorname{perm}(n)} \operatorname{sgn}(\sigma)A_{\sigma(1),\,1} \cdots A_{\sigma (n),\,n}\;.
$$


#### Theorem 2.5

$B$가 $A$의 임의의 두 rows을 exchange 한 행렬일 때 $\det B = -\det A$ 이다.

---

*(proof)* $B$가 $A$의 $i$-th row과 $j$-th row를  exchange 한 행렬임을 가정하자.  $i < j$ 라 가정해도 무방하다.  Group theory에 의해 $P = \{ \sigma \circ (i,\,j) : \sigma \in \operatorname{perm}(n) \}$ 이라 하면 $P=\operatorname{perm}(n)$ 이다. 따라서 $\sigma'=\sigma \circ (i,\,j)$ 라 하면, 
$$
\operatorname{sgn}(\sigma') B_{\sigma' (1),\,1}\cdots B_{\sigma'(i),\,i}\cdots B_{\sigma' (j),\,j}\cdots B_{\sigma'(n),\,n} = - \operatorname{sgn} (\sigma) A_{\sigma(1),\,1} \cdots A_{\sigma (j),\,i} \cdots A_{\sigma {i},\,j} \cdots A_{\sigma(n),\,n}
$$
이다. 따라서 $\det B = - \det A$ 이다. $\square$ 



#### Theorem 2.6

$A$의 $i$-th row와 $j$-th row가 같다면 $\det A=0$ 이다.

---

*(Proof)* . $B$를 $A$에서 $i$-th row와 $j$-th row를 exchange 한 것이라고 하자. $B=A$ 이므로 $\det B=\det A$ 이다 그러나 theorem 2.5에 의해 $\det B= -\det A$ 이어야 한다. 따라서 $\det A=0$. $\square$



#### Theorem  2.7

$\det A^T=\det A$. 

---

*(Proof)* (1) $\operatorname{perm}(n)$ 은 $\mathbb{Z}_n \to \mathbb{Z}_n$ bijection의 집합이므로 모든 $\sigma \in \operatorname{perm}(n)$ 에 대해 $\sigma^{-1}$ 이 존재하며 $\sigma^{-1}\in \operatorname{perm} (n)$ 이다. 그리고 $P = \{ \sigma^{-1} : \sigma \in \operatorname{perm}(n)\}= \operatorname{perm }(n)$ 이다. cyclic decomposition을 고려하면 , $\sigma = (a^1_1,\ldots,\,a^1_{n_1})\cdots (a^k_1,\,\ldots,\,a^k_{n_k})$ 이면 $\sigma^{-1} = (a^1_{n_1},\ldots,\,a^1_1)\cdots (a^k_{n_k},\ldots,\,a^k_1)$ 이다. 따라서 $\operatorname{sgn}(\sigma) = \operatorname{sgn}(\sigma^{-1})$ 이다. 
$$
\begin{align*}
\det A^T &= \sum_{\sigma \in \operatorname{perm} (n)}\operatorname{sgn}(\sigma)A_{1,\,\sigma (1)} \cdots A_{n,\,\sigma (n)} \\
&= \sum_{\sigma\in \operatorname{perm}(n)} \operatorname{sgn}(\sigma^{-1})A_{\sigma^{-1}(1),\,1} \cdots A_{\sigma^{-1}(n),\,n} \\
&= \det A.
\end{align*}
$$


#### Corollary 2.8

$B$가 $A$의 two columns를 exchange 한 행렬이면 $\det B=-\det A$ 이다. $A$의 두 column이 같다면 $\det A=0$ 이다.

---

*obvious from theorem 2.7 and 2.8*



#### Definition : Determinant of Column vectors.

$k,\,n$이 양의 정수이고 $1\le k \le n$ 이라 하자. $A_1,\ldots,\,A_n$ 이 각각 $n \times 1$ 행렬 일 때 행렬 $A$를 각각의 $A_i$를 $i$-th column으로 갖는 $n \times n$ 행렬이라 하자. 이 때 $\det (A_1,\ldots,\,A_n)$을 $\det A$로 정의한다.  



#### Theorem 2.9

$A_1,\ldots,\,A_n$ 이 각각 $n \times 1$ 행렬이고 $A'_k$ 도 $n\times 1$ 행렬이며 $c\in \mathbb{F}$ 라 하자. . 이 때 다음이 성립한다.

$$
\det (A_1,\ldots,\,A_k+cA'_k,\ldots,\,A_n)= \det (A_1,\ldots,\,A_k,\ldots,\,A_n)+ c\det(A_1,\ldots,\,A'_k,\ldots,\,A_n)
$$

---

*(Proof)* From the definition of determinant,
$$
\begin{align*}
\det(A_1,\ldots,\,&A_k+cA'_k,\ldots,\,A_n) = \sum_{\sigma\in \operatorname{perm}(n)} \operatorname{sgn}(\sigma)A_{\sigma(1),1}\cdots (A_{\sigma (k),k} +c A'_{\sigma (k),\,k})\cdots A_{\sigma (n),\,n} \\
&= \sum_{\sigma \in \operatorname{perm}(n)} \operatorname{sgn}(\sigma) \left[A_{\sigma(1),1}\cdots A_{\sigma (k),k} \cdots A_{\sigma (n),\,n}+cA_{\sigma(1),1}\cdots A'_{\sigma (k),k} \cdots A_{\sigma (n),\,n}\right] \\
&= \det(A_1,\ldots,A_k,\ldots,\,A_n) + c\det(A_1,\ldots,\,A_{k-1},\,A'_k,\,A_{k+1},\ldots,A_n)\;. \quad \square
\end{align*}
$$



#### Theorem 2.10

$A,\,B$가 각각 $n\times n$ 행렬일 때 $\det (AB) = (\det A)(\det B)$ 이다.

---

*(Proof)* (1) $n\times n$ 행렬에서 $A^i$를 $i$-th row of $A$, $A_j$ 를 $j$-th column of $A$ 라 하면 $(AB)_{i,\,j}=A^i B_j$ 이며 
$$
\det (AB)  = \det \left(\begin{bmatrix}A^1B_1 & \cdots& A^1B_n  \\
\vdots & \ddots&  \vdots \\ A^n B_1 & \cdots & A^nB_n\end{bmatrix}\right),  \quad (AB)_i = \begin{bmatrix}A^1B_i \\ \vdots \\ A^n B_i\end{bmatrix}
$$
이다.  
$$
(AB)_i= \begin{bmatrix} A^1B_i \\ \vdots \\A^nB_i \end{bmatrix} = \begin{bmatrix} \sum\limits_{k=1}^nA_{1k}B_{ki} \\ \vdots \\ \sum\limits_{k=1}^n A_{nk}B_{ki}\end{bmatrix} = \left(\sum_{k_i=1}^nB_{k_i,i}A_k \right)
$$

이므므로,
$$
\begin{align*}
\det(AB) &= \sum_{k_1=1}^n \cdots \sum_{k_n=1}^n B_{k_1,1}\ldots B_{k_n,\,n}\det(A_{k_1},\ldots,\,A_{k_n}) \\
&= \sum_{k_1=1}^n \cdots \sum_{k_n=1}^n \operatorname{sgn}(k_1,\ldots,\,k_n)B_{k_1,\,1}\cdots B_{k_n,\,n}(\det A ) \\
&= (\det A) \cdot \sum_{(k_1,\ldots,\,k_n)\in \operatorname{perm}(n)} \operatorname{sgn}(k_1,\ldots,\,k_n)B_{k_1,\,1}\cdots B_{k_n,\,n} \\
&= \det(A) \det (B)\;.\quad \square
\end{align*}
$$


#### Corollary 2.11

$A,\,B$가 $n \times n$ 행렬일 때, $\det (AB)= \det (BA)$ 이다.

----

*(Proof is trivial)*



#### Theorem 2.12

$T\in \mathcal{L}(V)$ 일 때 $\det T$ 는 basis independent 하다.

---

*(proof)*. Let $B_1=(v_1,\ldots,\,v_n)$ and $B_2=(u_1,\ldots,\,u_n)$ be a basis of $V$. Let $A=\mathcal{M}(T,\,B_1)$ and $B=\mathcal{M}(T,\,B_2)$. Define $S\in \mathcal{L}(V)$ s.t. $Su_i = v_i$. Then, $Tv_i = S^{-1}TSu_i$ 이므로 $C=\mathcal{M}(S,\,B_2,\,B_1)$ 이라 하면 $A= C^{-1}BC$ 이며 $ \det A = \det (C^{-1}BC)=\det(BCC^{-1})=\det B$. $\square$



#### Corollary 2.13

$T\in \mathcal{L}(V)$ 일 때 $\det T=\det \mathcal{M}(T)$ 이다. 

---

*Proof is trivial*



#### Theorem 2.14

$V$가 finite dimensional inner product space 이고 $S\in \mathcal{L}(V)$가 isometry 이면 $|\det S|=1$ 이다.

---

*(Proof)*  $S$가 isometry 이므로 $SS^{\dagger}=S^\dagger S=I$.이다. $(S^\dagger)_{i,\,j} =\overline{S_{ji}}$ 이므로 $\det S^\dagger = \overline{\det S}$.  

$\det SS^\dagger=(\det S)(\overline{\det S})=|\det S|^2=1$ 이므로 $|\det S|=1$. $\square$



#### Lemma 2.15

$V$가 inner product space 이고 $T\in \mathcal{L}(V)$ 일 때 $\det \sqrt{T^\dagger T}\ge 0$ 이다.

---

*(proof)* $T^\dagger T$ is an hermitian in $V$. 따라서 $T^\dagger T$의 orthonormal eigenvectors로 이루어진 basis of $V$ $e_1,\ldots,\,e_n$ 이 존재한다. $T^\dagger Te_i = \lambda_i e_i$ 라 하면 $\lambda_i = \langle e_i |T^\dagger Te_i \rangle = \|Te_i\|^2 \ge 0$. $\sqrt{T^\dagger T}e_i = \sqrt{\lambda_i} e_i $ for all $i=1\ldots,\,n$ 이고 $\det \sqrt{T^\dagger T} = \prod_{i=1}^n \sqrt{\lambda_i}\ge 0$. $\quad\square$ 



#### Lemma 2.16

$V$가 inner product space 이고 $T\in \mathcal{L}(V)$ 일 때, $|\det T| = \det \sqrt{T^\dagger T}$ 이다.

---

*(Proof)*. From polar decomposition, $T=S\sqrt{T^\dagger T}$ 를 만족하는 isometry $S$가 존재한다. 따라서,

$$
|\det T|=|\det S|\cdot \left|\det \sqrt{T^\dagger T}\right|= |\det \sqrt{T^\dagger T}| = \det \sqrt{T^\dagger T}\;. \quad\square
$$



#### Exercise (Chap. 10. B)

<b>1. </b> $V$가 real vector space 이고 $T\in \mathcal{L}(V)$ 이며 $T$는 eigenvalues를 갖지 않는다면 $\det T>0$ 임을 보이시오.

---

Complexification 한 $T_C$를 생각하면 $T_C$가 real eigenvlaues를 갖지 않고 $\lambda \in \mathbb{C}$가 eigenvalue of $T$ 이면 $\overline{\lambda}$ 도 eigenvalues 이다. $\det T$는 product of every eigenvalues including multiplicies 이므로 $\prod |\lambda|^2$ 의 꼴이다. 따라서 $\det T>0$ 이다.



<b>2. </b> $V$가 real vector space 이고 $\dim V$는 even integer 라 하자. $\det T<0$ 이면 $T$는 최소한 두개의 서로 다른 eigenvalues를 가짐을 보이시오.

---

$\det T<0$이므로 $T$는 $0$을 eigenvalues로 갖지 않는다. $\det T<0$ 이면 exercise 1. 로 부터 $T$가 eigenvlaues를 가짐을 알 고 있다. $T$의 characteristic polynomial $\chi_T(z) = \left( \prod\limits_{k=1}^m (z-\lambda_k) \right) \left( \prod\limits_{j=1}^n (z^2+2b_j z+c_j)\right)$  where $\lambda_k \in \mathbb{R}$ for every $k=1,\ldots,\,m$ and $b_j^2-c_j <0$ for all $j=1,\ldots,\,n$ 이다. $\deg \chi_T = \dim V$ 가 even number 이므로 $\deg\left(\prod_{k=1}^m (z-\lambda_k)\right) $ 도 even 이다. 

만약 eigenvalue가 하나 분이라면 $\chi_T(z) = (z-\lambda)^{2m} \left( \prod\limits_{j=1}^n (z^2+2b_j z+c_j)\right)$ 인데 그렇다면 $\det T>0$. 따라서 최소한 2개의 eigenvalues를 가진다.



<b>3. </b> $T\in \mathcal{L}(V)$ 이고 $n=\dim V >2$ 이다. $\lambda_1,\ldots,\,\lambda_n$이 eigenvalues of $T$ (or of $T_C$ if $V$ is real vector space) 라 하자. 이 list of eigenvalues는 multiplicity를 포함한다. $\chi_T(z)$를 characteristic polynomial of $T$ 라 하자. 

(a) $\chi_T(z)$ 의 $z^{n-2}$ term 의 계수를 $\lambda_1,\ldots,\,\lambda_n$ 을 이용하여 표현하시오. 

(b) $\chi_T(z)$의 $z$ term의 계수를 $\lambda_1,\ldots,\,\lambda_n$을 이용하여 표현하시오.

----

$\chi_T(z) = \prod\limits_{i=1}^n (z-\lambda_i)$. Define $S=\{ (i_1,\ldots,\,i_{n-1}): 1 \le i_k \le n, \, \text{every entries in the index are all distinct}\}$.
$$
\begin{align*}
\chi_T (z) &= {\textstyle \prod\limits_{i=1}^n}(z-\lambda_i) \\
&=z^n + (-1)^n({\textstyle \sum\limits_{i=1}^n}\lambda_i)z^{n-1}+ ({\textstyle \sum\limits_{i \ne j}}\lambda_i \lambda_j)z^{n-2} + \cdots + (-1)^n ({\textstyle \sum\limits_{i_1,\ldots,\,i_{n-1}\in S}} \lambda_{i_1}\ldots\lambda_{i_{n-1}})z \\
&\quad \quad + (-1)^n(\det T)
\end{align*}
$$


<b>4. </b> $T\in \mathcal{L}(V)$ 이고 $c\in \mathbb{F}$ 일 때 $\det (cT)= c^{\dim V}(\det T)$ 임을 보이시오.

---

Let $A=\mathcal{M}(T,\,B)$ for some basis $B$ of $V$. Let $A_i$ be the $i$-th row of $A$. 
$$
\begin{align*}
\det (cT) &= \det (cA) = \det (cA_1,\, cA_2,\ldots,\,cA_n) \\
&= c\det (A_1,\,cA_2,\ldots,\,cA_n)= \cdots = c^{\dim V}\det (A_1,\ldots,\,A_n)= c^{\dim V}\det A \\
&= c^{\dim V}(\det T).\quad\square
\end{align*}
$$


<b>5. </b> $S,\,T \in \mathcal{L}(V)$ 일 때 $\det (S+T)\ne \det S+ \det T$ 인 예륻 드시오.

---

Let $V=\mathbb{R}^2$ and define $S$ and $T$ in the standard basis as $Se_1=e_1$, $Se_2=0$, $Te_1=0$, $Te_2=e_2$. $\det S=\det T=0$ and $\det (S+T) = \det I_2 = 1$. 



<b>6. </b> $A$가 다음과 같은 block upper-triangular matrix 라 하자.
$$
A=\begin{bmatrix}A_1 & & \ast \\ & \ddots & \\ & & A_m\end {bmatrix}\;.
$$
여기서 $A_i$는 square matrix 이다. 이 때 $\det A=\prod_{j=1}^m (\det (A_j))$ 임을 보이시오.

---

(1) Let $A=\begin{bmatrix}A_1 & 0 \\ 0 & A_2\end{bmatrix}$. $A_1$ 은 $n_1 \times n_1$ 행렬이고 , $A_2$는 $n_2 \times n_2$ 행렬이라 하자. $I_1$을 $n_1 \times n_1$ identity matrix, $I_2$를 $n_2 \times n_2$ identity matrix 라 하면 $A=\begin {bmatrix} I_1 & 0 \\ 0 & A_2\end{bmatrix} \begin{bmatrix} A_1 & 0 \\ 0 & I_2\end{bmatrix}$  이다.

(2) $B_1=\begin{bmatrix} I_1 & 0 \\ 0 & A_2 \end{bmatrix}$ 을 생각하자. $\mathbb{F}^{n_1+n_2}$ vector space 에서 $V$ 는 두 $B_1$-invariant subspace의 direct sum 이다. 이로부터 $\det B_1 = \det A_2$ 임을 알 수 있다. 또한 $\det A= (\det A_1) (\det A_2)$ 임을 알 수 있다.

(3) 따라서
$$
\begin{align*}
\det A & = \det\left(\begin{bmatrix} A_1 & & \ast \\ & \ddots & \\ & & A_{m-1}\end{bmatrix}\right)(\det A_m) \\
&= \det \left( \begin{bmatrix} A_1 & & \ast \\ & \ddots & \\ & & A_{m-2} \end{bmatrix}\right) (\det A_{m-2})(\det A_{m-1}) \\
&\quad\quad\quad\vdots \\
&=\prod_{j=1}^m (\det A_j) \quad \square
\end{align*}
$$
<b>7. </b> $A$가 $n\times n$ real matrix  이고 $S\in \mathcal{L}(\mathbb{C}^n)$ 이 어떤  basis에서 $\mathcal{M}(S)=A$ 라 하자. $T\in \mathcal{M}(\mathbb{R}^n)$ 또한 어떤 basis 에서 $\mathcal{M}(T)=A$ 라 하자. 그렇다면 $\operatorname{tr} T=\operatorname{tr} S$ 이며 $\det T=\det S$ 임을 보이시오.

---

정의에 의해 $\det T=\det T_C$ , $\operatorname{tr}T=\operatorname{tr}T_C$ 이다. 또한 $\mathcal{M}(T)=\mathcal{M}(T_C)=A$ 이다. 따라서 trace와 dependent는 basis-independent 하므로 $\operatorname{tr}S= \operatorname{tr}T_C =\operatorname{tr}T$ 이며 $\det S=\det T_C=\det T$ 이다.



<b>8. </b>$\det T^\dagger  = \overline{\det T}$ 임을 보이시오. 이 결과를 이용하여 $|\det T| = \det \sqrt{T^\dagger T}$ 임을 lemma 2.5~2.6과 다르게 보이시오.

---

Let $A$ be the matrix of $T$ in a basis. Define $\overline{A}$ by $\overline{A}_{ij} = \overline{A_{ij}}$.  Then, 

$$
\det T^\dagger = \det A^\dagger = \det(\overline{A})^T=\det \overline{A}=\overline{\det A}  = \overline{\det T}. \quad \square
$$

 

